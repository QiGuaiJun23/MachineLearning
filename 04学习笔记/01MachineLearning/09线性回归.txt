回归问题的判定：

	目标值是一个连续型数据

分类的数据是离散的

房价预测、销售额预测、贷款额度（与决策树那个不同）

回归：
			迭代算法
神经网络：



算法       策略（损失函数）    优化

线性回归     误差平方和      正规方程

			最小二乘法      梯度下降

sklearn线性回归正规方程、梯度下降API
	
	sklearn.linear_model.LinearRegression    正规方程

	coef_：回归系数

	sklearn.linear_model.SGDRegressor        梯度下降

	coef_：回归系数


scikit-learn：

	优点：封装好，建立模型简单，预测简单

	缺点：算法的过程不知道，有些参数都在算法API内部优化

tensorflow：封装高低，自己实现线性回归，学习率等等

波士顿房价数据案例分析流程：

	1、波士顿地区房价数据获取

	2、波士顿地区房价数据分割

	3、训练与测试数据标准化处理

	4、使用最简单的线性回归模型LinearRegression和梯度下降估计SGDRegress对房价进行预测


回归性能评估：

	均方误差（Mean Squared Error）MSE评价机制

sklearn回归评估API：

	sklearn.metrics.mean_squared_error 

		mean_squared_error(y_true,y_pred)

			均方误差回归损失

			y_true：真实值

			y_pred：预测值

			return：浮点数结果




     梯度下降                                        正规方程
 
   需要选择学习率                                    不需要

   需要多次迭代                                      一次运算得出

   当特征数量n大时也能较好适用                    需要计算（XTX）-1

   												如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为O(n3)，通常来说当n<10000时还是可以接受的。

   适用于各种类型的模型                           只适用于线性模型，不适用逻辑回归模型	                                           等其他模型


LinearRegression与SGDRegressor评估：

	特点：线性回归器是最为简单、易用的回归模型。从某种程度上限制了使用，尽管如此，在不知道特征之间关系的前提下，我们仍然使用线性回归器作为大多数系统的首要选择。

	小规模数据:LinearRegression（不能解决拟合问题）以及其他

	大规模数据：SGDRegressor

过拟合与欠拟合：

	过拟合：一个假设在训练数据上能够获得比其他假设更好的拟合，但是在训练数据外的数据集上却

	不能很好的拟合数据，此时认为这个假设出现了过拟合的现象。（模型过于复杂）

	欠拟合：一个假设在训练数据上不能获得更好的拟合，但是在训练数据外的数据集上也不能很好的

	拟合数据，此时认为这个假设出现了欠拟合的现象。（模型过于简单）

对线性模型进行训练学习会变成复杂模型


线性回归： 线性关系数据

		  非线性关系     系数 


模型的复杂原因是：数据的特征和目标值之间的关系不仅仅是线性关系

欠拟合原因及解决办法：

	原因：学习到数据的特征较少

	解决方法：增加数据的特征数量


过拟合原因及解决办法：

	原因：原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点

	解决办法：

		进行特征选择，消除关联性大的特征（很难做）

		交叉验证（让所有数据都有过训练）

		正则化（重点）

根据结果现象判断：欠拟合、过拟合

 交叉验证：训练集结果：变表现不行

		测试集：变现不行

		欠拟合


特征选择：

	过滤式：低方差特征

	嵌入式：正则化、决策树、神经网络

L2正则化

	作用：可以使得W的每个元素都很小，都接近于0

	优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象


回归：解决过拟合的方式

线性回归API：LinearRegression容易出现过拟合，为了把训练集数据表现更好

L2正则化：Ridge：岭回归   带有正则化的线性回归，解决过拟合


带有正则化大的线性回归-Ridge

sklearn.linear_model.Ridge(alpha=1.0)

	具有L2正则化的线性最小二乘法

	alpha：正则化力度（超参数） 0~1  1~10

	coef_：回归系数

线性回归LinearRegression与Ridge对比：

	岭回归：回归得到的回归系数更符合实际，更可靠。另外，能让估计参数的波动范围变小，变得更稳定。在存在病态数据偏多的研究中有较大的使用价值。

