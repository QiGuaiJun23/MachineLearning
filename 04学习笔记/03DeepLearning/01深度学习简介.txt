神经网络的扩展

深度学习与计算机视觉

颜色通道：R、G、B

挑战：照射角度、光照强度、形状改变、部分遮蔽、背景混入

常规套路：

	1、收集数据并给定标签

	2、训练一个分类器

	3、测试、评估

	def train(train_images,train_labels):

		return model

	def predict(model,test_images):

		return test_labels


权重参数


Softmax分类器：（不知道满足，任何输入都有损失值）

	损失函数：交叉熵损失

	其输入值是一个向量，向量中元素为任意实数的评分值

	输出一个向量，其中每个元素值在0到1之间，且所有元素之和为1



前向传播：输入数据---->Loss  (BP算法)

反向传播：

Bachsize通常是2的整数倍(32,64,128):在数据集中一次取出Bachsize的数据

Epoch：训练集都跑完一遍叫做一个Epoch

一次迭代：完成一个Bachsize的前向传播和反向传播的过程

学习率：learning rate，通常设置的比较小

神经网络两部分：前向和反向

最优化是在反向传播中得出的

反向传播：链式法则


加法门单元：均等分配

MAX门单元：给最大的

乘法门单元：互换的感觉